num_feature: 68

batch_size: 64
model_dim: 128
ffn_dim: 128
drop_out: 0.3
num_heads: 4
num_layers: 2
max_epoch: 3
loss_lambda: 1.5
lr: 0.0005

experiment_name: